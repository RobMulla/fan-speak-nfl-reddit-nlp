{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language modeling is the task of predicting the next word, given the preceding history.\n",
    "\n",
    "### Sentiment detection is just a special case of classification\n",
    "\n",
    "**Data sets with fields:**\n",
    "\n",
    "*Combined_Comments* := comment_id, author, author_flair, score, comment_name, comment_fullname, comment_is_root, comment_parent, comment_created, comment_created_utc, comment_created_utc_datetime, comment_created_utc_date, comment_created_utc_time, comment_depth, comment_body, submission_id, submission_title, submission_created_utc**\n",
    "\n",
    "*Clean_Game_Data* := index, unnamed: 0, playnum, playid, 'Game Title Date', text, homeWinPercentage, matched_play_by_play_text, matched_play_by_play_index, matched_play_by_play_utc, matched_play_by_play_tweetid, home_team, away_team, awayWinPercentage\n",
    "\n",
    "*Pickle files in Clean_Game_Data* := author, author_flair, score, comment_id, comment_name, comment_fullname, comment_is_root, comment_parent, comment_approved_at_utc, comment_approved_by, matched_play_by_play_utc, matched_play_by_play_tweetid, home_team, away_team, awayWinPercentage, vader_ss, vader_neg, vader_neu, vader_pos, vader_compound\n",
    "\n",
    "*Comments_FanOfGame* := comment_body (from Reddit), fan_of_team_playing\n",
    "\n",
    "\n",
    "**Ideas for data to model**\n",
    "\n",
    "*-------------1-------------*\n",
    "\n",
    "*Dependent var* := game state\n",
    "\n",
    "*Independent vars* := comment_body, fan_of_team_playing\n",
    "\n",
    "*-------------2-------------*\n",
    "\n",
    "*Dependent var* := fan_of_team_playing\n",
    "\n",
    "*Independent vars* := comment_body, game_state\n",
    "\n",
    "*-------------3-------------*\n",
    "\n",
    "*Dependent var* := author_flair\n",
    "\n",
    "*Independent vars* := comment_body, game_fan_state (fan_team_prob_win, fan_team_prob_lose, fan_no_team)\n",
    "\n",
    "*-------------4-------------*\n",
    "\n",
    "*Dependent var* := author_game_state or game_fan_state (fan_team_prob_win, fan_team_prob_lose, fan_no_team)\n",
    "\n",
    "*Independent vars* := comment_body\n",
    "\n",
    "*-------------5-------------*\n",
    "\n",
    "*Dependent var* := next word\n",
    "\n",
    "*Independent vars* := previous word\n",
    "\n",
    "\n",
    "*--------------------------*\n",
    "\n",
    "*Next step* := apply language model to each game and examine by game_state, fan_of_team_playing\n",
    "\n",
    "**Possible comment label combinations (author_game_state)**\n",
    "\n",
    "*fan/close*\n",
    "\n",
    "*fan/blowout*\n",
    "\n",
    "*notfan/close*\n",
    "\n",
    "*notfan/blowout*\n",
    "\n",
    "*fan/lose*\n",
    "\n",
    "*fan/win*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chadharness/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/chadharness/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# NLTK libs\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load comments by game\n",
    "files = [\n",
    "    'Bears_vs_Packers__2017-09-28_comment_sentiment.pickle',\n",
    "    'Broncos_vs_Chiefs__2017-10-30_comment_sentiment.pickle',\n",
    "    'Chargers_vs_Cowboys__2017-11-23_comment_sentiment.pickle',\n",
    "    'Chiefs_vs_Patriots__2017-09-07_comment_sentiment.pickle',\n",
    "    'Chiefs_vs_Raiders__2017-10-19_comment_sentiment.pickle',\n",
    "    'Cowboys_vs_Cardinals__2017-09-25_comment_sentiment.pickle',\n",
    "    'Cowboys_vs_Raiders__2017-12-17_comment_sentiment.pickle',\n",
    "    'Eagles_vs_Panthers__2017-10-12_comment_sentiment.pickle',\n",
    "    'Falcons_vs_Buccaneers__2017-12-18_comment_sentiment.pickle',\n",
    "    'Falcons_vs_Patriots__2017-10-22_comment_sentiment.pickle',\n",
    "    'Falcons_vs_Seahawks__2017-11-20_comment_sentiment.pickle',\n",
    "    'Giants_vs_Cowboys__2017-09-10_comment_sentiment.pickle',\n",
    "    'Jaguars_vs_Patriots__2018-01-21_comment_sentiment.pickle',\n",
    "    'Lions_vs_Giants__2017-09-18_comment_sentiment.pickle',\n",
    "    'Lions_vs_Packers__2017-11-06_comment_sentiment.pickle',\n",
    "    'Packers_vs_Panthers__2017-12-17_comment_sentiment.pickle',\n",
    "    'Packers_vs_Vikings__2017-10-15_comment_sentiment.pickle',\n",
    "    'Patriots_vs_Dolphins__2017-12-11_comment_sentiment.pickle',\n",
    "    'Raiders_vs_Eagles__2017-12-25_comment_sentiment.pickle',\n",
    "    'Raiders_vs_Redskins__2017-09-24_comment_sentiment.pickle',\n",
    "    'Rams_vs_49ers__2017-09-21_comment_sentiment.pickle',\n",
    "    'Redskins_vs_Chiefs__2017-10-02_comment_sentiment.pickle',\n",
    "    'Redskins_vs_Cowboys__2017-11-30_comment_sentiment.pickle',\n",
    "    'Redskins_vs_Eagles__2017-10-23_comment_sentiment.pickle',\n",
    "    'Saints_vs_Falcons__2017-12-07_comment_sentiment.pickle',\n",
    "    'Saints_vs_Vikings__2017-09-11_comment_sentiment.pickle',\n",
    "    'Seahawks_vs_Cardinals__2017-11-09_comment_sentiment.pickle',\n",
    "    'Steelers_vs_Bengals__2017-12-04_comment_sentiment.pickle',\n",
    "    'Steelers_vs_Lions__2017-10-29_comment_sentiment.pickle',\n",
    "    'Texans_vs_Bengals__2017-09-14_comment_sentiment.pickle',\n",
    "    'Vikings_vs_Packers__2017-12-23_comment_sentiment.pickle',\n",
    "    'Vikings_vs_Panthers__2017-12-10_comment_sentiment.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Bears_vs_Packers__2017-09-28_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Broncos_vs_Chiefs__2017-10-30_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Chargers_vs_Cowboys__2017-11-23_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Chiefs_vs_Patriots__2017-09-07_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Chiefs_vs_Raiders__2017-10-19_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Cowboys_vs_Cardinals__2017-09-25_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Cowboys_vs_Raiders__2017-12-17_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Eagles_vs_Panthers__2017-10-12_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Falcons_vs_Buccaneers__2017-12-18_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Falcons_vs_Patriots__2017-10-22_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Falcons_vs_Seahawks__2017-11-20_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Giants_vs_Cowboys__2017-09-10_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Jaguars_vs_Patriots__2018-01-21_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Lions_vs_Giants__2017-09-18_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Lions_vs_Packers__2017-11-06_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Packers_vs_Panthers__2017-12-17_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Packers_vs_Vikings__2017-10-15_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Patriots_vs_Dolphins__2017-12-11_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Raiders_vs_Eagles__2017-12-25_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Raiders_vs_Redskins__2017-09-24_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Rams_vs_49ers__2017-09-21_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Redskins_vs_Chiefs__2017-10-02_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Redskins_vs_Cowboys__2017-11-30_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Redskins_vs_Eagles__2017-10-23_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Saints_vs_Falcons__2017-12-07_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Saints_vs_Vikings__2017-09-11_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Seahawks_vs_Cardinals__2017-11-09_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Steelers_vs_Bengals__2017-12-04_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Steelers_vs_Lions__2017-10-29_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Texans_vs_Bengals__2017-09-14_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Vikings_vs_Packers__2017-12-23_comment_sentiment.pickle\n",
      "/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/Vikings_vs_Panthers__2017-12-10_comment_sentiment.pickle\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/chadharness/mids/w266/w266_final_project/Clean_Game_Data/\"\n",
    "\n",
    "for index, filename in enumerate(files):\n",
    "    print(path+filename)\n",
    "    if index == 0:\n",
    "        data = pd.read_pickle(path+filename)\n",
    "        #print(data.head())\n",
    "    else:\n",
    "        temp_data = pd.read_pickle(path+filename)\n",
    "        data = data.append(temp_data)\n",
    "        #print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair</th>\n",
       "      <th>score</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_name</th>\n",
       "      <th>comment_fullname</th>\n",
       "      <th>comment_is_root</th>\n",
       "      <th>comment_parent</th>\n",
       "      <th>comment_approved_at_utc</th>\n",
       "      <th>comment_approved_by</th>\n",
       "      <th>...</th>\n",
       "      <th>matched_play_by_play_utc</th>\n",
       "      <th>matched_play_by_play_tweetid</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>awayWinPercentage</th>\n",
       "      <th>vader_ss</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Street_Spirit_</td>\n",
       "      <td>Raiders</td>\n",
       "      <td>2</td>\n",
       "      <td>dnnfsxx</td>\n",
       "      <td>t1_dnnfsxx</td>\n",
       "      <td>t1_dnnfsxx</td>\n",
       "      <td>True</td>\n",
       "      <td>7344it</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-09-29 00:30:01</td>\n",
       "      <td>9.135615e+17</td>\n",
       "      <td>Packers</td>\n",
       "      <td>Bears</td>\n",
       "      <td>0.161</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irishkid46</td>\n",
       "      <td>Bears</td>\n",
       "      <td>1</td>\n",
       "      <td>dnnft5a</td>\n",
       "      <td>t1_dnnft5a</td>\n",
       "      <td>t1_dnnft5a</td>\n",
       "      <td>True</td>\n",
       "      <td>7344it</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-09-29 00:30:01</td>\n",
       "      <td>9.135615e+17</td>\n",
       "      <td>Packers</td>\n",
       "      <td>Bears</td>\n",
       "      <td>0.161</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SportsMasterGeneral</td>\n",
       "      <td>Bears</td>\n",
       "      <td>12</td>\n",
       "      <td>dnnft8q</td>\n",
       "      <td>t1_dnnft8q</td>\n",
       "      <td>t1_dnnft8q</td>\n",
       "      <td>True</td>\n",
       "      <td>7344it</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-09-29 00:30:01</td>\n",
       "      <td>9.135615e+17</td>\n",
       "      <td>Packers</td>\n",
       "      <td>Bears</td>\n",
       "      <td>0.161</td>\n",
       "      <td>{'neg': 0.278, 'neu': 0.722, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Street_Spirit_</td>\n",
       "      <td>Raiders</td>\n",
       "      <td>24</td>\n",
       "      <td>dnnftgx</td>\n",
       "      <td>t1_dnnftgx</td>\n",
       "      <td>t1_dnnftgx</td>\n",
       "      <td>True</td>\n",
       "      <td>7344it</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-09-29 00:30:01</td>\n",
       "      <td>9.135615e+17</td>\n",
       "      <td>Packers</td>\n",
       "      <td>Bears</td>\n",
       "      <td>0.161</td>\n",
       "      <td>{'neg': 0.636, 'neu': 0.364, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fight_For_Tacos</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>dnnftkp</td>\n",
       "      <td>t1_dnnftkp</td>\n",
       "      <td>t1_dnnftkp</td>\n",
       "      <td>True</td>\n",
       "      <td>7344it</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-09-29 00:30:01</td>\n",
       "      <td>9.135615e+17</td>\n",
       "      <td>Packers</td>\n",
       "      <td>Bears</td>\n",
       "      <td>0.161</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_flair score comment_id comment_name  \\\n",
       "0       Street_Spirit_      Raiders     2    dnnfsxx   t1_dnnfsxx   \n",
       "1           irishkid46        Bears     1    dnnft5a   t1_dnnft5a   \n",
       "2  SportsMasterGeneral        Bears    12    dnnft8q   t1_dnnft8q   \n",
       "3       Street_Spirit_      Raiders    24    dnnftgx   t1_dnnftgx   \n",
       "4      Fight_For_Tacos         None     0    dnnftkp   t1_dnnftkp   \n",
       "\n",
       "  comment_fullname comment_is_root comment_parent comment_approved_at_utc  \\\n",
       "0       t1_dnnfsxx            True         7344it                    None   \n",
       "1       t1_dnnft5a            True         7344it                    None   \n",
       "2       t1_dnnft8q            True         7344it                    None   \n",
       "3       t1_dnnftgx            True         7344it                    None   \n",
       "4       t1_dnnftkp            True         7344it                    None   \n",
       "\n",
       "  comment_approved_by      ...        matched_play_by_play_utc  \\\n",
       "0                None      ...             2017-09-29 00:30:01   \n",
       "1                None      ...             2017-09-29 00:30:01   \n",
       "2                None      ...             2017-09-29 00:30:01   \n",
       "3                None      ...             2017-09-29 00:30:01   \n",
       "4                None      ...             2017-09-29 00:30:01   \n",
       "\n",
       "   matched_play_by_play_tweetid home_team away_team awayWinPercentage  \\\n",
       "0                  9.135615e+17   Packers     Bears             0.161   \n",
       "1                  9.135615e+17   Packers     Bears             0.161   \n",
       "2                  9.135615e+17   Packers     Bears             0.161   \n",
       "3                  9.135615e+17   Packers     Bears             0.161   \n",
       "4                  9.135615e+17   Packers     Bears             0.161   \n",
       "\n",
       "                                            vader_ss vader_neg vader_neu  \\\n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.000     1.000   \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.000     1.000   \n",
       "2  {'neg': 0.278, 'neu': 0.722, 'pos': 0.0, 'comp...     0.278     0.722   \n",
       "3  {'neg': 0.636, 'neu': 0.364, 'pos': 0.0, 'comp...     0.636     0.364   \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.000     1.000   \n",
       "\n",
       "  vader_pos vader_compound  \n",
       "0       0.0         0.0000  \n",
       "1       0.0         0.0000  \n",
       "2       0.0        -0.5927  \n",
       "3       0.0        -0.5423  \n",
       "4       0.0         0.0000  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8784                                Fisher you fat fuck! \n",
       "8814    Hmm, looks like a bad spot, I think Smith got ...\n",
       "8825                           Yea, first down for sure. \n",
       "8843    God damn, our o-line is just terrible at run b...\n",
       "8860      Part of it is injuries to our interior o-line. \n",
       "Name: comment_body, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.author == 'Scaryclouds'].comment_body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author',\n",
       " 'author_flair',\n",
       " 'score',\n",
       " 'comment_id',\n",
       " 'comment_name',\n",
       " 'comment_fullname',\n",
       " 'comment_is_root',\n",
       " 'comment_parent',\n",
       " 'comment_approved_at_utc',\n",
       " 'comment_approved_by',\n",
       " 'comment_created',\n",
       " 'comment_created_utc',\n",
       " 'comment_created_utc_datetime',\n",
       " 'comment_created_utc_date',\n",
       " 'comment_created_utc_time',\n",
       " 'comment_banned_at_utc',\n",
       " 'comment_banned_by',\n",
       " 'comment_depth',\n",
       " 'comment_num_reports',\n",
       " 'comment_body',\n",
       " 'comment_body_parsed',\n",
       " 'submission_id',\n",
       " 'submission_title',\n",
       " 'submission_created_utc',\n",
       " 'playId',\n",
       " 'index',\n",
       " 'Unnamed: 0',\n",
       " 'playnum',\n",
       " 'Game Title Date',\n",
       " 'text',\n",
       " 'homeWinPercentage',\n",
       " 'matched_play_by_play_text',\n",
       " 'matched_play_by_play_index',\n",
       " 'matched_play_by_play_utc',\n",
       " 'matched_play_by_play_tweetid',\n",
       " 'home_team',\n",
       " 'away_team',\n",
       " 'awayWinPercentage',\n",
       " 'vader_ss',\n",
       " 'vader_neg',\n",
       " 'vader_neu',\n",
       " 'vader_pos',\n",
       " 'vader_compound']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify game state\n",
    "data['win_differential'] = abs(data.homeWinPercentage - data.awayWinPercentage)\n",
    "\n",
    "# Call it a win for away if away has same or higher win percentage\n",
    "data['win_team'] = np.where(data.awayWinPercentage >= data.homeWinPercentage, 'away', 'home')\n",
    "\n",
    "data['game_state'] = np.where(data.win_differential < 0.6, 'close', 'notclose')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify author affiliation to game\n",
    "data['fan_type'] = np.where(data.away_team == data.author_flair, 'away', \n",
    "                            np.where(data.home_team == data.author_flair, 'home', 'nofan'))\n",
    "\n",
    "data['author_team_state'] = np.where(data.fan_type == 'nofan', 'nopref',\n",
    "                                     np.where(data.win_team == data.fan_type, 'winning', 'losing'))\n",
    "\n",
    "data['author_game_state'] = np.where(data.fan_type == 'nofan', \n",
    "                                     np.where(data.game_state == 'notclose', 'nofan_notclose', 'nofan_close'),\n",
    "                                     np.where(data.game_state == 'notclose', \n",
    "                                             np.where(data.win_team == data.fan_type, 'fan_win_notclose','fan_lose_notclose'),\n",
    "                                              np.where(data.win_team == data.fan_type, 'fan_win_close', 'fan_lose_close')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed some functions from the w266 utils.py file\n",
    "# Miscellaneous helpers\n",
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten a list-of-lists into a single list.\"\"\"\n",
    "    return list(itertools.chain.from_iterable(list_of_lists))\n",
    "\n",
    "\n",
    "# Word processing functions\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "    return word\n",
    "\n",
    "def canonicalize_word(word, wordset=None, digits=True):\n",
    "    word = re.sub(r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*)*\\/?\\S\", \\\n",
    "                                     \"postedhyperlinkvalue\", word)\n",
    "    #if not word.isupper():\n",
    "    word = word.lower()\n",
    "    if digits:\n",
    "        if (wordset != None) and (word in wordset): return word\n",
    "        word = canonicalize_digits(word) # try to canonicalize numbers\n",
    "    if (wordset == None) or (word in wordset):\n",
    "        return word\n",
    "    else:\n",
    "        return constants.UNK_TOKEN\n",
    "\n",
    "def canonicalize_words(words, **kw):\n",
    "    return [canonicalize_word(word, **kw) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(data, only_fans=False, no_empty=True, tail_win_diffs=False, tokenizer=TweetTokenizer(), canonize=True):\n",
    "    use_data = data\n",
    "    \n",
    "    if only_fans:\n",
    "        # Get rid of non-fans\n",
    "        use_data = use_data[use_data['fan_type']!='nofan']\n",
    "    \n",
    "    if no_empty:\n",
    "        # Eliminate data with empty comments\n",
    "        use_data = use_data[pd.notnull(use_data['comment_body'])]\n",
    "        \n",
    "    if tail_win_diffs:\n",
    "        # Eliminate data for games in which the outcome is neither very close nor very clear\n",
    "        use_data = use_data[(use_data['win_differential'] <= 0.2) | (use_data['win_differential'] >= 0.9)]\n",
    "\n",
    "    # Separate comments\n",
    "    comments = use_data.loc[:, 'comment_body']\n",
    "    \n",
    "    # Convert to list\n",
    "    comment_list = comments.values.tolist()\n",
    "    \n",
    "    # Tokenize comments\n",
    "    tokenizer = tokenizer\n",
    "    x_tokens = [tokenizer.tokenize(sentence) for sentence in comment_list]\n",
    "    \n",
    "    if canonize:\n",
    "        comments_canon = []\n",
    "        for token in x_tokens:\n",
    "            x_tokens_canon = canonicalize_words(token)\n",
    "            comments_canon.append(x_tokens_canon)\n",
    "        x_tokens = comments_canon\n",
    "    \n",
    "    return use_data, comments, comment_list, x_tokens\n",
    "\n",
    "\n",
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=10):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn_class1:\n",
    "        print (class_labels[0], coef, feat)\n",
    "\n",
    "    print()\n",
    "\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print (class_labels[1], coef, feat)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we'll remove games that are neither clear blowouts nor very close. We'll also restrict ourselves solely to tweets by users who self-identify as a fan, i.e. with flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data, comments, comment_list, x_tokens = make_data(data, only_fans=True, tail_win_diffs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "{'close': 41287, 'notclose': 41743}\n"
     ]
    }
   ],
   "source": [
    "# Isolate the labels\n",
    "# target_var = 'author_game_state'\n",
    "target_var = 'game_state'\n",
    "# target_var = 'fan_type'\n",
    "\n",
    "labels = use_data.loc[:, target_var]\n",
    "\n",
    "counts = {}\n",
    "for label in np.unique(labels):\n",
    "    counts[label] = sum(labels == label)\n",
    "\n",
    "print(\"Class counts:\\n{}\".format(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83030\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count or TF-IDF vectorize, removing stop words.\n",
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', lowercase=False, \n",
    "                             tokenizer=lambda text: text)\n",
    "                             #tokenizer=lambda text: text, min_df=0.00002, max_df=0.005)\n",
    "spmat = vectorizer.fit_transform(x_tokens)\n",
    "#vectorizer = CountVectorizer(analyzer='word', stop_words='english', lowercase=False, binary=False)\n",
    "#spmat = vectorizer.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and train\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(spmat, labels, test_size=0.10, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "#a_values = [x * 0.01 for x in range(1,20)]\n",
    "#gs_mnb = GridSearchCV(MultinomialNB(), {'alpha': a_values}, cv=5,\n",
    "#                       scoring='f1_weighted')\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_labels)\n",
    "#print(gs_mnb.best_estimator_)\n",
    "#print(gs_mnb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37124. 37603.]\n"
     ]
    }
   ],
   "source": [
    "print(clf.class_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['close' 'notclose']\n"
     ]
    }
   ],
   "source": [
    "# Get feature names and class labels\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "class_labels = clf.classes_\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 62.45%\n",
      "Test Data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      close      0.633     0.597     0.615      4163\n",
      "   notclose      0.617     0.652     0.634      4140\n",
      "\n",
      "avg / total      0.625     0.624     0.624      8303\n",
      "\n",
      "Confusion Matrix...\n",
      "[[2487 1676]\n",
      " [1442 2698]]\n"
     ]
    }
   ],
   "source": [
    "# Create predictions and evaluate\n",
    "pred_labels = clf.predict(test_data)\n",
    "acc = metrics.accuracy_score(test_labels, pred_labels)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))\n",
    "print('Test Data:')\n",
    "\n",
    "print(classification_report(test_labels, pred_labels, target_names = class_labels, digits=3))\n",
    "\n",
    "print(\"Confusion Matrix...\")\n",
    "confusionMatrix = metrics.confusion_matrix(test_labels, pred_labels)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close -11.631221128427331 ###bruh\n",
      "close -11.631221128427331 ###mods\n",
      "close -11.631221128427331 ##crazyeyes\n",
      "close -11.631221128427331 ##domcapers\n",
      "close -11.631221128427331 ##firegarret\n",
      "close -11.631221128427331 ##mikeshula\n",
      "close -11.631221128427331 ##questions\n",
      "close -11.631221128427331 ##superbowl\n",
      "close -11.631221128427331 ##touchdowwwnnnnn\n",
      "close -11.631221128427331 #DG-DG\n",
      "close -11.631221128427331 #DGDGDG\n",
      "close -11.631221128427331 #DGDGDGDG\n",
      "close -11.631221128427331 #allplayersmatter\n",
      "close -11.631221128427331 #amanprovides\n",
      "close -11.631221128427331 #analysis\n",
      "\n",
      "notclose -3.7345662013167704 .\n",
      "notclose -4.480346151869599 ,\n",
      "notclose -4.653306298418179 ?\n",
      "notclose -4.938916378626684 !\n",
      "notclose -5.132103883964338 game\n",
      "notclose -5.24887573474587 fuck\n",
      "notclose -5.391043107401303 ...\n",
      "notclose -5.401783677654522 just\n",
      "notclose -5.464980463381548 like\n",
      "notclose -5.470774039206745 DG\n",
      "notclose -5.537343488204635 lol\n",
      "notclose -5.589333104013729 fucking\n",
      "notclose -5.639432134852957 \"\n",
      "notclose -5.686479232631074 ’\n",
      "notclose -5.690631974203936 good\n"
     ]
    }
   ],
   "source": [
    "# Get most informative features\n",
    "most_informative_feature_for_binary_classification(vectorizer, clf, n = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize data and split into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse data prep, vectorization, and train/test split from Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "lgreg = LogisticRegression()\n",
    "lgreg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 62.41%\n",
      "Test Data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      close      0.622     0.638     0.630      4163\n",
      "   notclose      0.626     0.610     0.618      4140\n",
      "\n",
      "avg / total      0.624     0.624     0.624      8303\n",
      "\n",
      "Confusion Matrix...\n",
      "[[2657 1506]\n",
      " [1615 2525]]\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = lgreg.predict(test_data)\n",
    "acc = metrics.accuracy_score(test_labels, pred_labels)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))\n",
    "print('Test Data:')\n",
    "\n",
    "print(classification_report(test_labels, pred_labels, target_names = class_labels, digits=3))\n",
    "#print(classification_report(test_labels, pred_labels, target_names = ['fan_lose_close', 'fan_lose_notclose', 'fan_win_close', 'fan_win_notclose'], digits=3))\n",
    "\n",
    "print(\"Confusion Matrix...\")\n",
    "confusionMatrix = metrics.confusion_matrix(test_labels, pred_labels)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close -3.083387276589751 vernon\n",
      "close -2.916989858090347 foles\n",
      "close -2.8505547414694385 kalil\n",
      "close -2.8432073438532317 shazier\n",
      "close -2.432569510986005 roberts\n",
      "close -2.426465896113813 ebron\n",
      "close -2.4129499304235984 lattimore\n",
      "close -2.3960654682452986 ab\n",
      "close -2.2481388899302264 bersin\n",
      "close -2.21636704437944 quin\n",
      "close -2.1637725459347292 bucs\n",
      "close -2.1589079406201903 bounds\n",
      "close -2.1510923780674727 hightower\n",
      "close -2.143273609819304 apple\n",
      "close -2.136422235009551 mills\n",
      "\n",
      "notclose 6.252775706009352 glennon\n",
      "notclose 6.03267734586043 fog\n",
      "notclose 5.171237599217078 bears\n",
      "notclose 4.623512584117515 trevathan\n",
      "notclose 4.115676250470464 gg\n",
      "notclose 3.5019565157239745 trubisky\n",
      "notclose 3.4708362362954452 siemian\n",
      "notclose 3.4060403898708485 jordy\n",
      "notclose 3.316606566691688 onside\n",
      "notclose 3.157677110168431 obj\n",
      "notclose 3.1377404645144775 mcadoo\n",
      "notclose 3.0058498218298153 fox\n",
      "notclose 2.9109852692522082 shutout\n",
      "notclose 2.7888360139763946 marshall\n",
      "notclose 2.716301040827279 achilles\n"
     ]
    }
   ],
   "source": [
    "# Get top features\n",
    "# Get most informative features\n",
    "most_informative_feature_for_binary_classification(vectorizer, lgreg, n = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulate the problem as a regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by using the same data that we used for classification. We will later model all of the tweets in our corpus. In both cases, our target variable will be win_differential, a continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data, comments, comment_list, x_tokens = make_data(data, only_fans=True, tail_win_diffs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'win_differential'\n",
    "y_data = use_data.loc[:, target_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize data and split into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will vectorize a bit differently for regression. We will use binary variables to indicate the presence or absence of a word, rather than model counts or tf-idf, as we did for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', stop_words='english', tokenizer=lambda text: text, \n",
    "                             lowercase=False, binary=True)#, min_df=10)\n",
    "spmat = vectorizer.fit_transform(x_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and train\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(spmat, y_data, test_size=0.10, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83030\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.39\n",
      "Test set score: -0.18\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = lr.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(test_data, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25816,)\n",
      "Top feats:\n",
      "pairing roadrunner faaaaast schiavo hinders okayish cursory physifally sleuths tri-state yrs kalifa chamionship nintendo va pleaseee baaaaaad comings sported urinatingtree\n",
      "Bottom feats:\n",
      "namath's richardwashington toothpaste taunts compulsively preference syrup exhange skeletons described sportsbook nord septum virgil hahahahahahahahahahahahahahahahahahahahahahahahahahahahahhahahahajahahajhahajajajajajjahahahahhahahahahahahahhahahahahhahahahahajhajajajhahahhahah economy sturgill identifiable swayed chevrolet\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "n = 20\n",
    "print(lr.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(lr.coef_)[-n:]\n",
    "print(\"Top feats:\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(lr.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0002, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.0002)\n",
    "lasso.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.06\n",
      "Test set score: 0.05\n",
      "Number of features used: 239\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = lasso.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(test_data, test_labels)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25816,)\n",
      "Top feats:\n",
      "achilles end hundley angle camera jordy ap fox packers capers onside siemian obj mcadoo adams trevathan bears glennon gg fog\n",
      "Bottom feats:\n",
      "foles ebron shazier bounds penalty penalties tackle kamara ab gronk ben drive eagles weak gruden vernon coverage stafford todd dak\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "m = 20\n",
    "n = np.sum(lasso.coef_ != 0)\n",
    "if m < n:\n",
    "    n = m\n",
    "print(lasso.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(lasso.coef_)[-n:]\n",
    "print(\"Top feats:\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(lasso.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdg = Ridge(alpha=5)\n",
    "rdg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.25\n",
      "Test set score: 0.09\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = rdg.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(rdg.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(rdg.score(test_data, test_labels)))\n",
    "#print(\"Number of features used: {}\".format(np.sum(clf.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25816,)\n",
      "Top Feats\n",
      "naz mcadoo hyde marshall touchback legion postedhyperlinkvalueei=7bqqwq2cbssq_qbb1jtobg&q=28-3+falcons&oq=28-3&gs_l=postedhyperlinkvalue achilles doink siemian shutout trevathan callahan glennon jordy onside gg colt postedhyperlinkvaluev=fr9uj_ayayq&feature=postedhyperlinkvaluet=10s fog\n",
      "Bottom feats:\n",
      "vernon kalil mccourty quin hightower pagano roberts bersin foles cart foreman remmers morelli dupree week's strief trufant barry tree jameis\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "n = 20\n",
    "print(rdg.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(rdg.coef_)[-n:]\n",
    "print(\"Top Feats\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(rdg.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0001, copy_X=True, fit_intercept=True, l1_ratio=0.25,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elnet = ElasticNet(alpha=0.0001, l1_ratio=0.25)\n",
    "elnet.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.13\n",
      "Test set score: 0.09\n",
      "Number of features used: 2534\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = elnet.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(elnet.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(elnet.score(test_data, test_labels)))\n",
    "print(\"Number of features used: {}\".format(np.sum(elnet.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25816,)\n",
      "Top Feats\n",
      "turkey touchback obj parker marshall van ap bears shutout mcadoo colt postedhyperlinkvaluev=fr9uj_ayayq&feature=postedhyperlinkvaluet=10s siemian achilles trevathan jordy onside glennon gg fog\n",
      "Bottom feats:\n",
      "kalil vernon quin hightower foles roberts lattimore ebron shazier mccourty anthem pagano runoff ab bersin barry trufant carrie apple dupree\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "m = 20\n",
    "n = np.sum(elnet.coef_ != 0)\n",
    "if m < n:\n",
    "    n = m\n",
    "print(elnet.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(elnet.coef_)[-n:]\n",
    "print(\"Top Feats\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(elnet.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun regressions against the full corpus of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data, comments, comment_list, x_tokens = make_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588378\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'win_differential'\n",
    "y_data = use_data.loc[:, target_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize data and split into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will require that each word appear in at least five posts, in order to make the problem a bit more tractable. The full vocabulary is ~73,000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', stop_words='english', tokenizer=lambda text: text, \n",
    "                             lowercase=False, binary=True, min_df=5)\n",
    "spmat = vectorizer.fit_transform(x_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588378, 20293)\n"
     ]
    }
   ],
   "source": [
    "print(spmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and train\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(spmat, y_data, test_size=0.10, random_state=42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.12\n",
      "Test set score: 0.04\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = lr2.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(lr2.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(lr2.score(test_data, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20293,)\n",
      "Top Feats\n",
      "ruby postedhyperlinkvaluepostedhyperlinkvalue naz unified sorrow smithfest postedhyperlinkvalueei=7bqqwq2cbssq_qbb1jtobg&q=28-3+falcons&oq=28-3&gs_l=postedhyperlinkvalue mmmphmmgofgpsngfjg panting wilfs recruits try-hard selena mcfucked plagued mcaddo blossoms cbssports suckle postedhyperlinkvaluewiki_political_.2f_religious_comments\n",
      "Bottom feats:\n",
      "proverbs addlepated septum ヽ pagano's ʖ kat dissonance +DGDG:DGDG fortnight demean lisa's ving truf gano's alualu wendell utc usain eifert's\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "n = 20\n",
    "print(lr2.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(lr2.coef_)[-n:]\n",
    "print(\"Top Feats\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(lr2.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0002, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2 = Lasso(alpha=0.0002)\n",
    "lasso2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.02\n",
      "Test set score: 0.02\n",
      "Number of features used: 83\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = lasso2.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(lasso2.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso2.score(test_data, test_labels)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso2.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20293,)\n",
      "Top Feats\n",
      "won romo season hundley siemian game angle team rodgers broncos mcadoo giants trevathan fumble adams packers gg bears fog glennon\n",
      "Bottom feats:\n",
      "jags watson penalties bortles penalty gronk shazier flag bengals smith refs tackle drive commercial flags anthem hate catch pi half\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "m = 20\n",
    "n = np.sum(lasso2.coef_ != 0)\n",
    "if m < n:\n",
    "    n = m\n",
    "print(lasso2.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(lasso2.coef_)[-n:]\n",
    "print(\"Top Feats\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(lasso2.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdg2 = Ridge(alpha=5)\n",
    "rdg2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.11\n",
      "Test set score: 0.06\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = rdg2.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(rdg2.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(rdg2.score(test_data, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20293,)\n",
      "Top Feats\n",
      "vance siemien thumbs laterals joystick trevethan siemian bellamy glennon travathan postedhyperlinkvalueei=7bqqwq2cbssq_qbb1jtobg&q=28-3+falcons&oq=28-3&gs_l=postedhyperlinkvalue shutout gamblers semen shutouts pouncey trevathan paxton postedhyperlinkvaluev=fr9uj_ayayq&feature=postedhyperlinkvaluet=10s fog\n",
      "Bottom feats:\n",
      "clowney jurassic jeter mathieu devey usain edp bersin veldheer goldblum ving ldt starz eifert morrow dinosaurs fozzy headbutted sudfeld trufant\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "n = 20\n",
    "print(rdg2.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(rdg2.coef_)[-n:]\n",
    "print(\"Top Feats\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(rdg2.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0001, copy_X=True, fit_intercept=True, l1_ratio=0.25,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elnet2 = ElasticNet(alpha=0.0001, l1_ratio=0.25)\n",
    "elnet2.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.05\n",
      "Test set score: 0.05\n",
      "Number of features used: 1022\n"
     ]
    }
   ],
   "source": [
    "#Create predictions and evaluate\n",
    "pred_labels = elnet2.predict(test_data)\n",
    "print(\"Training set score: {:.2f}\".format(elnet2.score(train_data, train_labels)))\n",
    "print(\"Test set score: {:.2f}\".format(elnet2.score(test_data, test_labels)))\n",
    "print(\"Number of features used: {}\".format(np.sum(elnet2.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20293,)\n",
      "Top Feats\n",
      "turkey jordy fox xp lambeau semen marshall shutout adams thumbs trubisky lightning onside gg achilles bears siemian trevathan glennon fog\n",
      "Bottom feats:\n",
      "ebron vernon clowney kamara watson lattimore larry shazier foles intro carrie legs deuce computer texans anthem palmer cooper trump mixon\n"
     ]
    }
   ],
   "source": [
    "# Look at top scoring words\n",
    "m = 20\n",
    "n = np.sum(elnet2.coef_ != 0)\n",
    "if m < n:\n",
    "    n = m\n",
    "print(elnet2.coef_.shape)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "top_feats = np.argsort(elnet2.coef_)[-n:]\n",
    "print(\"Top Feats\")\n",
    "print(\" \".join(feature_names[j] for j in top_feats))\n",
    "\n",
    "bottom_feats = np.argsort(elnet2.coef_)[:n]\n",
    "print(\"Bottom feats:\")\n",
    "print(\" \".join(feature_names[j] for j in bottom_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
